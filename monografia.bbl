\providecommand{\abntreprintinfo}[1]{%
 \citeonline{#1}}
\setlength{\labelsep}{0pt}\begin{thebibliography}{}
\providecommand{\abntrefinfo}[3]{}
\providecommand{\abntbstabout}[1]{}
\abntbstabout{v-1.9.7 }

\bibitem[Blei, Ng e Jordan 2003]{Blei_2003}
\abntrefinfo{Blei, Ng e Jordan}{BLEI; NG; JORDAN}{2003}
{BLEI, D.~M.; NG, A.~Y.; JORDAN, M.~I. Latent dirichlet allocation.
\textbf{Journal of Machine Learning Research}, MIT Press, v.~3, n.~Jan, p. 993--1022, 2003.
ISSN 1532-4435.
Dispon{\'\i}vel em: \url{http://jmlr.org/papers/v3/blei03a.html}.}

\bibitem[Datchanamoorthy, S e B 2023]{Datchanamoorthy_2023}
\abntrefinfo{Datchanamoorthy, S e B}{DATCHANAMOORTHY; S; B}{2023}
{DATCHANAMOORTHY, K.; S, A. M.~G.; B, P. Text mining: Clustering using bert and probabilistic topic modeling.
\textbf{Social Informatics Journal}, 2023.
Dispon{\'\i}vel em: \url{https://api.semanticscholar.org/CorpusID:267122800}.}

\bibitem[Deerwester \textit{et al.} 1990]{Deerwester_1990}
\abntrefinfo{Deerwester \textit{et al.}}{DEERWESTER \textit{et al.}}{1990}
{DEERWESTER, S. \textit{et al.} Indexing by latent semantic analysis.
\textbf{Journal of the American Society for Information Science}, v.~41, n.~6, p. 391--407, 1990.
Dispon{\'\i}vel em: \url{https://asistdl.onlinelibrary.wiley.com/doi/abs/10.1002/\%28SICI\%291097-4571\%28199009\%2941\%3A6\%3C391\%3A\%3AAID-ASI1\%3E3.0.CO\%3B2-9}.}

\bibitem[Devlin \textit{et al.} 2019]{Devlin_2019}
\abntrefinfo{Devlin \textit{et al.}}{DEVLIN \textit{et al.}}{2019}
{DEVLIN, J. \textit{et al.} \textbf{BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}. 2019.
Dispon{\'\i}vel em: \url{https://arxiv.org/abs/1810.04805}.}

\bibitem[Galli \textit{et al.} 2024]{Galli_2024}
\abntrefinfo{Galli \textit{et al.}}{GALLI \textit{et al.}}{2024}
{GALLI, C. \textit{et al.} Topic modeling for faster literature screening using transformer-based embeddings.
\textbf{Metrics}, v.~1, n.~1, 2024.
ISSN 3042-5042.
Dispon{\'\i}vel em: \url{https://www.mdpi.com/3042-5042/1/1/2}.}

\bibitem[George e Sumathy 2023]{George_2023}
\abntrefinfo{George e Sumathy}{GEORGE; SUMATHY}{2023}
{GEORGE, L.; SUMATHY, P. An integrated clustering and bert framework for improved topic modeling.
\textbf{International Journal of Information Technology}, v.~15, n.~4, p. 2187--2195, 2023.
Dispon{\'\i}vel em: \url{https://doi.org/10.1007/s41870-023-01268-w}.}

\bibitem[Grootendorst 2022]{Grootendorst_2022}
\abntrefinfo{Grootendorst}{GROOTENDORST}{2022}
{GROOTENDORST, M. \textbf{BERTopic: Neural topic modeling with a class-based TF-IDF procedure}. 2022.
Dispon{\'\i}vel em: \url{https://arxiv.org/abs/2203.05794}.}

\bibitem[Hofmann 1999]{Hofmann_1999}
\abntrefinfo{Hofmann}{HOFMANN}{1999}
{HOFMANN, T. Probabilistic latent semantic indexing. In:  \textbf{Proceedings of the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval}. Berkeley, CA, USA: ACM Press, 1999. p. 50--57.
ISBN 1-58113-096-1.}

\bibitem[Hofmann 2001]{Hofmann_2001}
\abntrefinfo{Hofmann}{HOFMANN}{2001}
{HOFMANN, T. Hofmann, t.: Unsupervised learning by probabilistic latent semantic analysis. machine learning 42(1-2), 177-196.
\textbf{Machine Learning}, v.~42, p. 177--196, 01 2001.}

\bibitem[Jurafsky e Martin 2009]{Jurafsky_2009}
\abntrefinfo{Jurafsky e Martin}{JURAFSKY; MARTIN}{2009}
{JURAFSKY, D.; MARTIN, J. \textbf{Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition}. Pearson Prentice Hall, 2009.  (Prentice Hall series in artificial intelligence).
ISBN 9780131873216. Dispon{\'\i}vel em: \url{https://books.google.com.br/books?id=fZmj5UNK8AQC}.}

\bibitem[Kim, Kogler e Maliphol 2024]{Kim_2024}
\abntrefinfo{Kim, Kogler e Maliphol}{KIM; KOGLER; MALIPHOL}{2024}
{KIM, K.; KOGLER, D.~F.; MALIPHOL, S. {Identifying interdisciplinary emergence in the science of science: combination of network analysis and BERTopic}.
\textbf{Palgrave Communications}, v.~11, n.~1, p. 1--15, December 2024.
Dispon{\'\i}vel em: \url{https://ideas.repec.org/a/pal/palcom/v11y2024i1d10.1057\_s41599-024-03044-y.html}.}

\bibitem[Manning e Schutze 1999]{Manning_1999}
\abntrefinfo{Manning e Schutze}{MANNING; SCHUTZE}{1999}
{MANNING, C.; SCHUTZE, H. \textbf{Foundations of Statistical Natural Language Processing}. MIT Press, 1999.  (Foundations of Statistical Natural Language Processing).
ISBN 9780262133609. Dispon{\'\i}vel em: \url{https://books.google.com.br/books?id=YiFDxbEX3SUC}.}

\bibitem[Mifrah e Benlahmar 2020]{Mifrah_2020}
\abntrefinfo{Mifrah e Benlahmar}{MIFRAH; BENLAHMAR}{2020}
{MIFRAH, S.; BENLAHMAR, E.~H. Topic modeling coherence: A comparative study between lda and nmf models using covidâ€™19 corpus.
\textbf{International Journal of Advanced Trends in Computer Science and Engineering}, 08 2020.}

\bibitem[Mikolov \textit{et al.} 2013]{Mikolov_2013}
\abntrefinfo{Mikolov \textit{et al.}}{MIKOLOV \textit{et al.}}{2013}
{MIKOLOV, T. \textit{et al.} \textbf{Efficient Estimation of Word Representations in Vector Space}. 2013.
Dispon{\'\i}vel em: \url{https://arxiv.org/abs/1301.3781}.}

\bibitem[Mohammadi e Karami 2020]{Mohammadi_2020}
\abntrefinfo{Mohammadi e Karami}{MOHAMMADI; KARAMI}{2020}
{MOHAMMADI, E.; KARAMI, A. Exploring research trends in big data across disciplines: A text mining analysis.
\textbf{Journal of Information Science}, v.~48, 06 2020.}

\bibitem[Pennington, Socher e Manning 2014]{Pennington_2014}
\abntrefinfo{Pennington, Socher e Manning}{PENNINGTON; SOCHER; MANNING}{2014}
{PENNINGTON, J.; SOCHER, R.; MANNING, C. {G}lo{V}e: Global vectors for word representation. In:  MOSCHITTI, A.; PANG, B.; DAELEMANS, W. (Ed.). \textbf{Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})}. Doha, Qatar: Association for Computational Linguistics, 2014. p. 1532--1543. Dispon{\'\i}vel em: \url{https://aclanthology.org/D14-1162}.}

\bibitem[Polyzos e Wang 2022]{Polyzos_2022}
\abntrefinfo{Polyzos e Wang}{POLYZOS; WANG}{2022}
{POLYZOS, E.; WANG, F. Twitter and market efficiency in energy markets: Evidence using lda clustered topic extraction.
\textbf{Energy Economics}, v.~114, p. 106264, 2022.
ISSN 0140-9883.
Dispon{\'\i}vel em: \url{https://www.sciencedirect.com/science/article/pii/S0140988322004017}.}

\bibitem[Radford e Narasimhan 2018]{Radford_2018}
\abntrefinfo{Radford e Narasimhan}{RADFORD; NARASIMHAN}{2018}
{RADFORD, A.; NARASIMHAN, K. Improving language understanding by generative pre-training. In:  . [s.n.], 2018. Dispon{\'\i}vel em: \url{https://api.semanticscholar.org/CorpusID:49313245}.}

\bibitem[Reimers e Gurevych 2019]{Reimers_2019}
\abntrefinfo{Reimers e Gurevych}{REIMERS; GUREVYCH}{2019}
{REIMERS, N.; GUREVYCH, I. \textbf{Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks}. 2019.
Dispon{\'\i}vel em: \url{https://arxiv.org/abs/1908.10084}.}

\bibitem[Taylor 1953]{Taylor_1953}
\abntrefinfo{Taylor}{TAYLOR}{1953}
{TAYLOR, W.~L. Cloze procedure: A new tool for measuring readability.
\textbf{Journalism Quarterly}, v.~30, p. 415--433, 1953.}

\bibitem[Vaswani \textit{et al.} 2017]{vaswani_2017}
\abntrefinfo{Vaswani \textit{et al.}}{VASWANI \textit{et al.}}{2017}
{VASWANI, A. \textit{et al.} \textbf{Attention Is All You Need}. 2017.
Dispon{\'\i}vel em: \url{https://arxiv.org/abs/1706.03762}.}

\bibitem[Wang, Hohman e Chau 2023]{Wang_2023}
\abntrefinfo{Wang, Hohman e Chau}{WANG; HOHMAN; CHAU}{2023}
{WANG, Z.~J.; HOHMAN, F.; CHAU, D.~H. \textbf{WizMap: Scalable Interactive Visualization for Exploring Large Machine Learning Embeddings}. 2023.
Dispon{\'\i}vel em: \url{https://arxiv.org/abs/2306.09328}.}

\bibitem[Xie \textit{et al.} 2020]{Xie_2020}
\abntrefinfo{Xie \textit{et al.}}{XIE \textit{et al.}}{2020}
{XIE, Q. \textit{et al.} Monolingual and multilingual topic analysis using lda and bert embeddings.
\textbf{Journal of Informetrics}, v.~14, n.~3, p. 101055, 2020.
ISSN 1751-1577.
Dispon{\'\i}vel em: \url{https://www.sciencedirect.com/science/article/pii/S1751157719305127}.}

\end{thebibliography}
