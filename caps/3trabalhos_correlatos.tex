\chapter[TRABALHOS CORRELATOS]{TRABALHOS CORRELATOS}

A revisão da literatura permitiu reunir estudos e abordagens relevantes relacionados ao uso de técnicas de modelagem de tópicos e modelos de linguagem de grande escala aplicados à análise de publicações científicas. Essa análise fornece a base teórica necessária para sustentar o desenvolvimento desta pesquisa, permitindo identificar metodologias, técnicas e ferramentas já existentes que abordam problemas similares.

Nesse contexto, variadas estratégias de modelagem de tópicos foram empregadas para o mapeamento de tópicos de forma eficiente e inovadora. Por exemplo, \cite{Kozlowski} propõem uma abordagem que utiliza o \textit{BERTopic} \cite{Grootendorst} para gerar tópicos a partir de um conjunto de dados contendo todos os artigos científicos publicados por pesquisadores suíços no \textit{Web of Science}, utilizando um tamanho mínimo de cluster de 100 documentos para criar o modelo base de tópicos. Essa estratégia consiste em fornecer três diferentes \textit{LLMs} com as dez palavras-chave geradas pelo \textit{BERTopic} para representar cada tópico. Eles utilizaram o modelo \textit{flan} \cite{Chung}, da \textit{Google}, um modelo de linguagem generativo de código aberto, e o modelo \textit{GPT-4} da \textit{OpenAI} \cite{OpenAI} em sua versão completa, \textit{GPT-4o}, além da versão reduzida, \textit{GPT-4 mini}. Para cada um dos três modelos, eles testaram dois diferentes prompts para produzir, primeiramente, um rótulo de uma única palavra (\textit{single-word label}) e, em seguida, um rótulo com até três palavras (\textit{3-word label}).

Embora os modelos generativos, como o \textit{BERTopic}, demonstrem capacidade para criar rótulos sintéticos precisos e representativos para tópicos de pesquisa, essa capacidade depende da qualidade e definição dos tópicos. Assim, é necessário usar pelo menos três palavras para capturar a complexidade dos tópicos de pesquisa, gerando uma dependência da capacidade dos modelos generativos para criar rótulos sintéticos. Além disso, a precisão dos rótulos pode diminuir em espaços de tópicos maiores ou quando os tópicos não são bem definidos.

Seguindo uma linha de raciocínio semelhante, \cite{Meng} propõem uma abordagem que também utiliza o \textit{BERTopic} e o \textit{OpenAI GPT} para mapear a evolução da pesquisa científica dentro de um grande conjunto de dados de publicações relacionadas à \textit{DSM} (Demand-side energy management). Nesse caso, \textit{Meng} emprega o \textit{GPT} após a fase de processamento de dados para extrair características dos resumos e títulos dos artigos, aplicando as técnicas de \textit{embeddings} aos documentos da \textit{DSM}, mapeando cada publicação para um vetor de dimensão fixa. Dessa forma, todo o processamento de \textit{embeddings} é gerado pela API de \textit{Embeddings} do \textit{GPT}, ao invés do algoritmo padrão do \textit{BERTopic}, o \textit{S-BERT} \cite{Reimers}, garantindo uma maior qualidade das \textit{embeddings} geradas. Em seguida, o modelo \textit{BERTopic} é utilizado para classificar em dez temas principais que representam as principais áreas de pesquisa no campo. Eles realizam a clusterização dos tópicos nesse conjunto de vetores e executam a redução de dimensionalidade para representar visualmente a distribuição dos diferentes tópicos. Finalmente, a divisão de temas permite a criação de uma rede para cada tema e visualização, auxiliando na análise da literatura e na identificação de tópicos-chave e padrões de citação.

Com essa abordagem, foi possível identificar os artigos mais influentes e impactantes para cada tema, bem como discutir suas contribuições e implicações. Além disso, ela permitiu explorar o papel e o impacto da pesquisa interdisciplinar na \textit{DSM}, fornecendo insights e recomendações para direções futuras de pesquisa. Outra contribuição significativa foi o desenvolvimento de uma plataforma de análise bibliométrica baseada na web para apoiar o estudo da literatura da \textit{DSM}. Essa plataforma se destaca como uma ferramenta de software que permite coletar, processar, analisar e visualizar dados bibliométricos de diferentes campos e tópicos de pesquisa.

Alguns estudos expandiram o uso de ferramentas como o \textit{GPT} e algoritmos padrões do \textit{BERTopic}. Por exemplo, \cite{Gana} propõem um \textit{framework} semi-automático para revisões de literatura que integra modelos de \textit{LLMs}, como o \textit{SOLAR-10.7B} \cite{KimSolar}, com o \textit{BERTopic} e o \textit{KeyBERT} \cite{GrootendorstKeyBert}. Esse \textit{framework} utiliza o modelo de \textit{embedding} \textit{Bge-large-en-v1.5} \cite{Chen} para gerar representações semânticas precisas dos documentos, seguido de redução de dimensionalidade com \textit{UMAP} e \textit{clustering} com \textit{HDBSCAN} para identificar tópicos coesos. A extração de características é realizada por meio do \textit{c-TF-IDF}, que destaca palavras-chave únicas para cada cluster. O \textit{SOLAR-10.7B} é empregado para refinar a representação dos tópicos, gerando rótulos descritivos e selecionando documentos representativos. A eficácia do método foi comprovada por uma alta similaridade média de 69,56\% entre as palavras-chave geradas pelo \textit{KeyBERT} e as palavras-chave indexadas no \textit{Scopus}.

A escolha de ferramentas como o \textit{SOLAR-10.7B}, \textit{KeyBERT} e \textit{Bge-large-en-v1.5} foi fundamentada em sua eficácia comprovada em tarefas de \textit{NLP}, escalabilidade e integração perfeita com o \textit{pipeline} proposto. O \textit{framework} mostrou-se altamente adaptável a diferentes domínios, como medicina e segurança cibernética, e sua capacidade de lidar com grandes volumes de dados o torna uma solução robusta para revisões sistemáticas em campos de rápido crescimento.

Por outro lado, alguns estudos realizaram comparações entre os métodos tradicionais de modelagem de tópicos, como o \textit{LDA} e \textit{LSA}, e o \textit{BERTopic}. Por exemplo, \cite{Jung} empregaram métodos como \textit{Latent Dirichlet Allocation} (\textit{LDA}), \textit{Nonnegative Matrix Factorization} (\textit{NMF}), \textit{Combined Topic Model} (\textit{CTM}) e \textit{BERTopic} para analisar dados de mídia (\textit{LexisNexis}) e acadêmicos (\textit{Web of Science}). O \textit{BERTopic}, que combina \textit{embeddings} de texto gerados pelo \textit{BERT} com técnicas de redução de dimensionalidade (\textit{UMAP}) e \textit{clustering} (\textit{HDBSCAN}), demonstrou superioridade em diversidade e coesão de tópicos. Ele identifica tópicos mais precisos e coesos, destacando-se pela capacidade de capturar contextos semânticos complexos.

Os resultados destacam que o \textit{BERTopic} é eficiente por sua capacidade de reduzir dimensionalidade, agrupar documentos de forma robusta e representar tópicos de maneira clara e interpretável. Essa abordagem contribui para uma compreensão mais profunda das discussões em torno de \textit{LLMs}, fornecendo insights valiosos tanto para a academia quanto para o setor empresarial.

Seguindo a mesma linha de estudo, \cite{Wijanto} também exploraram técnicas avançadas de modelagem de tópicos em artigos científicos, com foco no ajuste de hiperparâmetros em modelos baseados em \textit{BERT}, incluindo o \textit{BERTopic}. A metodologia utilizada incorporou diversas etapas, desde o pré-processamento dos dados até a geração de tópicos, empregando \textit{embeddings} de palavras, redução de dimensionalidade e algoritmos de clusterização. Os \textit{embeddings} contextuais, como \textit{RoBERTa} e \textit{S-BERT} \cite{Reimers}, foram utilizados para capturar nuances semânticas nos textos, enquanto métodos de redução de dimensionalidade, como \textit{UMAP} e \textit{PCA} (Principal Component Analysis), facilitaram o agrupamento de tópicos. Entre os algoritmos de clusterização, destacaram-se o \textit{K-Means} \cite{MacQueen} e o \textit{HDBSCAN}, testados em diferentes configurações. A qualidade dos tópicos gerados foi avaliada por métricas de coerência semântica, como o \textit{UMass}, e os resultados foram visualizados por meio de mapas de distâncias intertópicos.

Os resultados indicaram que a combinação \textit{RoBERTa} \cite{Liu}, \textit{PCA} (Principal Component Analysis) e \textit{K-Means} gerou tópicos mais coerentes e interpretáveis em comparação a métodos tradicionais, como \textit{LDA}. Essa abordagem destacou-se ao capturar relações contextuais e subtópicos complexos nos artigos analisados, demonstrando eficácia computacional e profundidade semântica. Embora o método tenha superado técnicas probabilísticas em diversos aspectos, os autores enfatizaram que desafios permanecem, como a avaliação mais abrangente dos modelos baseados em \textit{BERT} e a generalização para diferentes domínios. Esses avanços reforçam o potencial do \textit{BERTopic} e de \textit{LLMs} para melhorar a análise temática e a descoberta de tendências em corpora científicos diversificados.

Diante da análise dos estudos apresentados, é possível observar um avanço significativo no uso de técnicas de modelagem de tópicos e de \textit{Large Language Models (LLMs)} para análise de publicações científicas. Ferramentas como o \textit{BERTopic}, aliadas a modelos de linguagem de última geração, demonstram eficiência na identificação de padrões semânticos, na geração de rótulos representativos e na visualização de tópicos. Contudo, ainda existem desafios, como a necessidade de ajustes finos de hiperparâmetros e a generalização dos métodos para diferentes contextos e domínios. A integração dessas tecnologias tem se mostrado promissora para expandir a análise temática e fomentar novas descobertas em diversos campos do conhecimento, reforçando sua relevância como base teórica e metodológica para o desenvolvimento desta pesquisa.

