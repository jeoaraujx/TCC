\chapter[TRABALHOS CORRELATOS]{TRABALHOS CORRELATOS}

A análise de grandes volumes de publicações científicas por meio de técnicas computacionais é um campo de pesquisa em franca expansão. A revisão da literatura, portanto, é fundamental para contextualizar e justificar a abordagem proposta neste trabalho — um \textit{pipeline} que integra \textit{BERTopic} e \textit{GPT-4} para análise do acervo da plataforma SIMCC. Os estudos selecionados a seguir validam as escolhas metodológicas deste projeto, demonstrando a superioridade de modelos de tópicos baseados em \textit{embeddings}, a flexibilidade de seus componentes e a sinergia promissora com \textit{Large Language Models} (LLMs) para enriquecimento semântico.

A decisão de utilizar o \textit{BERTopic} como ferramenta central de modelagem de tópicos é respaldada por estudos comparativos que atestam sua superioridade frente a abordagens tradicionais. A pesquisa de \citeonline{Jung_2024} é emblemática nesse sentido, ao realizar uma análise comparativa entre métodos como \textit{Latent Dirichlet Allocation} (LDA), \textit{Nonnegative Matrix Factorization} (NMF) e o \textit{BERTopic}, aplicando-os a dados acadêmicos e de mídia. Os autores concluíram que o \textit{BERTopic}, que combina \textit{embeddings} de texto com técnicas de redução de dimensionalidade e clusterização, "demonstrou superioridade em diversidade e coesão de tópicos" (\citeonline[p. 27]{Jung_2024}). Essa capacidade de capturar contextos semânticos complexos, superando a abordagem de "saco de palavras" (\textit{bag-of-words}) do LDA, é crucial para o objetivo dessa pesquisa, que é analisar a produção científica interdisciplinar e multilíngue da plataforma SIMCC. A eficácia do \textit{BERTopic} deriva de sua arquitetura, que se apoia em \textit{embeddings} de sentenças, como os gerados pelo \textit{Sentence-BERT} (\textit{SBERT}) (\citeonline{Reimers_2019}), para agrupar documentos com base na similaridade semântica, e não apenas na frequência lexical.

A arquitetura do \textit{BERTopic} não é apenas robusta, mas também modular, permitindo a exploração de diferentes configurações para otimizar os resultados, um ponto investigado por \citeonline{Wijanto_2024}. Em seu trabalho, os autores exploraram o ajuste de hiperparâmetros em modelos baseados em \textit{BERT}, testando combinações variadas de modelos de \textit{embedding} (como \textit{RoBERTa} e \textit{S-BERT}), técnicas de redução de dimensionalidade (\textit{UMAP} e \textit{PCA}) e algoritmos de clusterização (\textit{K-Means} e \textit{HDBSCAN}). Embora a combinação que eles identificaram como ótima (\textit{RoBERTa + PCA + K-Means}) divirja da utilizada neste projeto (\textit{S-BERT + UMAP + HDBSCAN}), o estudo reforça um ponto central: a importância da seleção criteriosa de cada componente do \textit{pipeline} para garantir a geração de tópicos coerentes e interpretáveis. A metodologia dessa pesquisa, portanto, adota a configuração padrão e amplamente validada do \textit{BERTopic} (\citeonline{Grootendorst_2022}), que utiliza \textit{UMAP} para preservação da estrutura topológica dos dados e \textit{HDBSCAN} pela sua capacidade de identificar \textit{clusters} de densidades variadas e lidar com ruído, sendo ideal para a heterogeneidade esperada nos dados da SIMCC.

Uma vez que os tópicos são \textit{clusterizados}, a etapa de rotulagem torna-se crítica para a interpretabilidade dos resultados. Abordagens tradicionais, baseadas apenas nas palavras-chave mais frequentes, frequentemente geram rótulos genéricos. A literatura recente aponta para o uso de LLMs como uma solução eficaz para este desafio. \citeonline{Kozlowski_2024} propõem uma abordagem que utiliza o \textit{BERTopic} para gerar tópicos e, em seguida, alimenta LLMs como o \textit{GPT-4} com as dez palavras-chave mais representativas de cada tópico para gerar rótulos automáticos. A conclusão dos autores alinha-se diretamente com a segunda etapa do nosso \textit{pipeline}: os modelos \textit{GPT-4} são capazes de rotular os tópicos de forma precisa e acurada, e "rótulos de 3 palavras são preferíveis para capturar a complexidade dos tópicos de pesquisa" (\citeonline{Kozlowski_2024}, p. 1). Este achado valida a hipótese central deste projeto de que o \textit{GPT-4} pode ser empregado para enriquecer semanticamente os \textit{clusters} identificados pelo \textit{BERTopic}, gerando rótulos descritivos que superam as limitações de métodos puramente estatísticos.

A integração de LLMs e \textit{BERTopic} em um \textit{pipeline} coeso para análise bibliométrica já foi validada em contextos similares. \citeonline{Meng_2024} propõem uma metodologia que também utiliza \textit{BERTopic} e \textit{GPT} para mapear a evolução da pesquisa científica em um grande volume de publicações. Notavelmente, os autores utilizam a API do \textit{GPT} para gerar os \textit{embeddings} dos documentos antes de aplicar o \textit{BERTopic}, em vez do \textit{S-BERT}, demonstrando a flexibilidade e as diferentes possibilidades de integração entre essas tecnologias. Além disso, o trabalho de (\citeonline{Meng_2024}) culmina no desenvolvimento de uma plataforma \textit{web} de análise bibliométrica para visualização de redes e tópicos, um objetivo análogo ao proposto nessa pesquisa com o uso da ferramenta \textit{WizMap} para exploração interativa dos resultados.

Seguindo uma linha similar, \citeonline{Gana_2024} apresentam um \textit{framework} semi-automático para revisões de literatura que integra LLMs (como o \textit{SOLAR-10.7B}), \textit{BERTopic} e \textit{KeyBERT}. O \textit{framework} utiliza um modelo de \textit{embedding} específico (\textit{Bge-large-en-v1.5}) e segue o \textit{pipeline} padrão do \textit{BERTopic} (\textit{UMAP} e \textit{HDBSCAN}) para identificar tópicos coesos. O LLM é então empregado para refinar a representação dos tópicos, gerando rótulos descritivos e selecionando documentos representativos. Assim como os estudos de (\citeonline{Meng_2024}) e \citeonline{Kozlowski_2024}, este trabalho reforça que a combinação de um modelo de tópicos moderno com um LLM constitui uma abordagem de ponta para a análise de literatura científica, validando a arquitetura geral do \textit{pipeline} proposto para a plataforma SIMCC.

Em suma, a análise dos trabalhos correlatos demonstra que a proposta desse projeto está firmemente ancorada em práticas e pesquisas recentes e relevantes. A literatura confirma a superioridade do \textit{BERTopic} sobre métodos tradicionais (\citeonline{Jung_2024}), destaca a importância da configuração de seu \textit{pipeline} modular (\citeonline{Wijanto_2024}) e valida o uso de LLMs como o \textit{GPT-4} para a tarefa de enriquecimento semântico dos tópicos gerados (\citeonline{Kozlowski_2024}). Além disso, \textit{frameworks} integrados, que combinam essas duas tecnologias, já foram aplicados com sucesso para mapear e analisar a produção científica (\citeonline{Meng_2024}; \citeonline{Gana_2024}). Este trabalho, portanto, avança ao aplicar essa metodologia de ponta a um contexto específico e de grande relevância regional — a base de dados da plataforma SIMCC —, com o objetivo de não apenas extrair conhecimento, mas também de disponibilizá-lo de forma interativa e visual.

\section{Síntese Comparativa dos Trabalhos Correlatos}

A fim de consolidar a análise da literatura e posicionar de forma clara a contribuição desta pesquisa, o quadro a seguir (Quadro \ref{tab:trabalhos_correlatos}) apresenta uma síntese comparativa dos trabalhos correlatos discutidos. A comparação é estruturada com base em critérios essenciais, como o objetivo principal de cada estudo, o pipeline metodológico empregado, as tecnologias de embedding e o uso específico de LLMs. Essa estrutura permite visualizar as sinergias e as particularidades de cada abordagem, destacando como este TCC se fundamenta e avança em relação ao estado da arte.

\begin{landscape}
\begin{table}[htbp]
\centering
\captionsetup{justification=centering}
\caption{Quadro Resumo: Comparativo de Trabalhos Correlatos}
\label{tab:trabalhos_correlatos}
\scriptsize
\resizebox{\linewidth}{!}{%
\begin{tabularx}{\linewidth}{l p{2.8cm} p{3.4cm} p{2.4cm} p{2.8cm} X}
\toprule
\textbf{Referência} & \textbf{Objetivo Principal} & \textbf{Pipeline/Método Utilizado} & \textbf{Modelo de Embedding} & \textbf{Uso do LLM} & \textbf{Relação com Esta Pesquisa} \\
\midrule
Jung et al. (2024) & Comparar o desempenho de modelos de tópicos (LDA, NMF, BERTopic) em textos acadêmicos e de notícias sobre LLMs. & Análise comparativa de métricas de coerência e diversidade dos tópicos gerados. & SBERT (implícito no BERTopic). & O estudo é \textit{sobre} LLMs, mas não os utiliza no pipeline. & Justifica a escolha do BERTopic, demonstrando sua superioridade sobre métodos tradicionais para analisar textos acadêmicos e capturar nuances semânticas. \\
\addlinespace
Wijanto, Widiastuti e Yong (2024) & Explorar o ajuste de hiperparâmetros e encontrar a configuração ótima para modelos de tópicos baseados em BERT em artigos científicos. & BERTopic com diferentes combinações de embeddings (RoBERTa, S-BERT), redução de dimensionalidade (UMAP, PCA) e clusterização (K-Means, HDBSCAN). & Testou múltiplos, incluindo S-BERT e RoBERTa. & Nenhum. O foco é na otimização do pipeline de modelagem de tópicos. & Valida a abordagem metodológica, mostrando que a seleção de cada componente do pipeline é uma etapa crucial. Reforça que a configuração usada neste TCC é uma das mais consolidadas. \\
\addlinespace
Kozlowski, Pradier e Benz (2024) & Avaliar a confiabilidade de diferentes LLMs para rotular automaticamente os tópicos gerados pelo BERTopic. & Pipeline em duas etapas: 1. Geração de tópicos com BERTopic; 2. Envio das palavras-chave para um LLM gerar o rótulo. & SBERT (implícito no BERTopic). & Rotulagem de Tópicos (usando flan, GPT-4 mini e GPT-4). & Justifica diretamente a segunda etapa do pipeline, confirmando que o GPT-4 é eficaz para criar rótulos descritivos e precisos. \\
\addlinespace
Meng et al. (2024) & Mapear a evolução de um campo de pesquisa científica utilizando uma abordagem integrada de LLM e modelagem de tópicos. & Pipeline integrado: 1. Geração de embeddings com a API do GPT; 2. Clusterização e modelagem com BERTopic. & GPT-3.5 (text-embedding-ada-002). & Geração de Embeddings e análise semântica. & Valida o conceito do pipeline completo (LLM + BERTopic). Apresenta uma arquitetura alternativa e reforça o objetivo de criar uma interface de visualização. \\
\addlinespace
Gana et al. (2024) & Propor um framework semi-automático para revisões de literatura, combinando LLMs e BERTopic. & Pipeline integrado: 1. Embedding com BGE; 2. Clusterização com BERTopic (UMAP + HDBSCAN); 3. Refinamento da representação dos tópicos com LLM. & BAAI/bge-large-en-v1.5. & Refinamento da Representação de Tópicos (usando SOLAR-10.7B). & Posiciona este TCC dentro de uma tendência de pesquisa de criar frameworks de análise. Mostra a flexibilidade do pipeline ao usar diferentes modelos. \\
\addlinespace
\textbf{Esta Pesquisa} & Analisar as publicações científicas da plataforma SIMCC para identificar padrões temáticos e facilitar a exploração visual do conhecimento. & Pipeline integrado: 1. SBERT; 2. BERTopic (UMAP + HDBSCAN); 3. GPT-4 para rotulagem; 4. Visualização com WizMap. & Sentence-BERT (paraphrase-multilingual-MiniLM-L12-v2). & Rotulagem e Enriquecimento Semântico de Tópicos (GPT-4). & Aplica um pipeline de ponta, validado pela literatura, a um conjunto de dados único (SIMCC) para resolver um problema prático de gestão do conhecimento. \\
\bottomrule
\end{tabularx}
}
\end{table}
\end{landscape}
