\chapter[INTRODUÇÃO]{INTRODUÇÃO}

O cenário da pesquisa científica registra um crescimento exponencial na produção acadêmica nas últimas décadas, gerando um volume de dados que impõe dificuldades aos métodos convencionais de organização e análise. Para navegar nesse vasto conjunto de informações, pesquisadores confiam majoritariamente em plataformas de busca baseadas em palavras-chave, como \textit{Web of Science}\footnote{Disponível em: \url{https://access.clarivate.com/login?app=wos}.}, \textit{Scopus}\footnote{Disponível em: \url{https://www.scopus.com/home.uri}.} e \textit{IEEE Xplore}\footnote{Disponível em: \url{https://ieeexplore.ieee.org/}.}. Contudo, essa abordagem de recuperação de informações é limitada pela ambiguidade e pela diversidade do léxico científico, o que pode dificultar o retorno de resultados completos e a identificação de \textbf{estruturas temáticas latentes} na literatura \cite{Galli_2024}.

Segundo \citeonline{Datchanamoorthy_2023}, a complexidade desses acervos e a necessidade de uma análise semântica profunda têm impulsionado a aplicação de técnicas avançadas de \gls{pln}. Essa integração entre Ciência da Informação, \gls{ia} e Linguística Computacional auxilia na construção de soluções mais robustas para a gestão do conhecimento acadêmico. Estudos como os de \citeonline{Mohammadi_2020} e \citeonline{Xie_2020}, que analisaram agrupamentos de pesquisa em \textit{Big Data} por meio de mineração de texto, destacam a relevância da integração de técnicas de modelagem de tópicos com modelos de linguagem baseados em transformadores.

A arquitetura de Transformadores, apresentada por \citeonline{vaswani_2017}, introduziu o mecanismo de autoatenção (\textit{self-attention}) no campo do \gls{pln}. Modelos subsequentes, como o \gls{bert}\footnote{Disponível em: \url{https://huggingface.co/docs/transformers/model_doc/bert}.}, proposto por \citeonline{Devlin_2019}, permitiram capturar relações contextuais bidirecionais em textos. A partir dessa base, consolidaram-se os \textit{embeddings}, representações vetoriais que codificam o significado semântico de palavras e frases, superando as limitações de modelos tradicionais de \textit{bag-of-words} e de abordagens probabilísticas clássicas como o \gls{lda} \cite{Galli_2024}.

Nesse contexto, a técnica \gls{bertopic}\footnote{Disponível em: \url{https://github.com/MaartenGr/BERTopic}.}, proposta por \citeonline{Grootendorst_2022}, surge como uma abordagem do estado da arte. Seu diferencial reside na utilização dos \textit{embeddings} contextuais para a clusterização de tópicos, permitindo a identificação de agrupamentos densos e o tratamento de nuances semânticas em textos interdisciplinares.

O foco desta pesquisa reside na instanciação de um artefato computacional para o mapeamento visual e interativo de publicações científicas. A proposta central consiste na integração da modelagem de tópicos do \gls{bertopic} com a ferramenta de visualização \gls{wizmap}\footnote{Disponível em: \url{https://github.com/poloclub/wizmap}.} \cite{Wang_2023}, aplicada ao contexto de dados regionais. O estudo de caso utiliza como base de validação (Prova de Conceito) o acervo do Núcleo de Pesquisa Aplicada e Inovação (NPAI), visando demonstrar a viabilidade da solução para futura expansão ao Observatório de Dados Públicos de Ciência e Tecnologia da Bahia\footnote{Disponível em: \url{https://simcc.uesc.br/observatorio}.}, plataforma que coleta informações de fontes como Currículos Lattes e \textit{OpenAlex}, fundamental na gestão do conhecimento científico do estado.

A metodologia \gls{dsr} é adotada como a estrutura condutora deste estudo, orientando a criação do \textit{pipeline} como o artefato principal. O objetivo é transformar a base de dados textual do NPAI/Observatório, atualmente explorada via listas estáticas, em um mapa de conhecimento navegável. Nessa solução, o \gls{bertopic} é empregado para extrair padrões temáticos a partir de títulos de publicações, e o \gls{wizmap} é utilizado para a exploração visual.

\section{Contribuições do Trabalho}
Este estudo caracteriza-se como uma pesquisa de natureza aplicada, enquadrada na \gls{dsr} como a instanciação de um artefato tecnológico em um contexto específico. Diferentemente de trabalhos que visam a inovação algorítmica pura, a contribuição central deste trabalho é técnica-regional, residindo na orquestração de componentes do estado da arte para oferecer uma arquitetura alternativa para a descoberta de temas no acervo de produção científica da Bahia.

As contribuições específicas podem ser estratificadas em:

\begin{enumerate}
    \item \textbf{Validação de Pipeline em Cenário Controlado (NPAI):} O estudo implementa e valida o \textit{pipeline} utilizando como base de teste o acervo do Núcleo de Pesquisa Aplicada e Inovação (NPAI). Esta aplicação piloto demonstrou a viabilidade técnica de transformar metadados estáticos em mapas de conhecimento navegáveis, servindo como prova de conceito (PoC) para a expansão ao acervo completo do Observatório.
    
    \item \textbf{Ferramenta de Orientação e Visibilidade para o Ecossistema Regional:} O artefato atua como um instrumento de direcionamento estratégico para pesquisadores e gestores da Bahia. Como uma alternativa à busca lexical, a visualização interativa amplia a visibilidade de áreas interdisciplinares frequentemente ofuscadas, permitindo que o usuário identifique conexões não óbvias entre diferentes domínios. Essa exploração por vizinhança semântica apoia diretamente o levantamento de novas hipóteses investigativas, revelando a topologia do conhecimento que servirá de norte para o fomento e desenvolvimento da produção científica local.
\end{enumerate}

\section{Organização do Trabalho}
O trabalho está organizado da seguinte forma: O Capítulo 2 estabelece o Referencial Teórico, abordando os conceitos de Ciência da Informação, a arquitetura dos Transformadores e as técnicas de modelagem de tópicos. A seguir, O Capítulo 3 analisa os Trabalhos Correlatos, contextualizando esta pesquisa frente ao estado da arte. O Capítulo 4 detalha a Metodologia baseada em \gls{dsr}. O Capítulo 5 descreve o Projeto de Desenvolvimento e a arquitetura do \textit{pipeline}. Por fim, o Capítulo 6 discute os Resultados e a avaliação da solução proposta.