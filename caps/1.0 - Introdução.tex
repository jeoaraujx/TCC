\chapter[INTRODUÇÃO]{INTRODUÇÃO}

O cenário da pesquisa científica registra um crescimento na produção acadêmica nas últimas décadas, gerando um volume de dados que impõe dificuldades aos métodos convencionais de organização e análise. Para navegar nesse conjunto de informações, pesquisadores confiam em plataformas de busca, como \textit{Web of Science}\footnote{Disponível em: \url{https://access.clarivate.com/login?app=wos}.}, \textit{Scopus}\footnote{Disponível em: \url{https://www.scopus.com/home.uri}.} e \textit{IEEE Xplore}\footnote{Disponível em: \url{https://ieeexplore.ieee.org/}.}, baseando-se majoritariamente em palavras-chave. Contudo, essa abordagem de recuperação de informações é limitada pela ambiguidade e pela diversidade do léxico científico, o que pode dificultar o retorno de resultados completos e a identificação de tendências na literatura \cite{Galli_2024}.

Segundo \citeonline{Datchanamoorthy_2023}, a complexidade desses acervos e a necessidade de uma análise mais profunda têm impulsionado a aplicação de técnicas avançadas de \gls{pln}. Essa integração entre ciência da informação, \gls{ia} e linguística computacional, auxilia na construção de soluções para a gestão do conhecimento acadêmico. Estudos como os de \citeonline{Mohammadi_2020} e \citeonline{Xie_2020}, que analisaram tendências de pesquisa em \textit{Big Data} por meio de mineração de texto, destacam a relevância da integração de técnicas de modelagem de tópicos com modelos baseados em transformadores.

A arquitetura de Transformadores, apresentada por \citeonline{vaswani_2017}, introduziu o mecanismo de autoatenção (\textit{self-attention}) no campo da \gls{pln}. Modelos subsequentes, como o \gls{bert}\footnote{Disponível em: \url{https://huggingface.co/docs/transformers/model_doc/bert}.}, proposto por \citeonline{Devlin_2019}, permitiram capturar relações contextuais em textos. A partir dessa base, surgiram os \textit{embeddings}, representações numéricas que codificam o significado semântico de palavras e frases, abordando as limitações de modelos tradicionais de \textit{bag-of-words} e de modelagem de tópicos como o \gls{lda} \cite{Galli_2024}.

Nesse contexto, a técnica de \gls{bertopic}\footnote{Disponível em: \url{https://github.com/MaartenGr/BERTopic}.}, proposto por \citeonline{Grootendorst_2022}, surge como uma abordagem atualizada. Seu diferencial reside na utilização dos \textit{embeddings} contextuais de modelos como o \gls{bert} para a modelagem de tópicos, permitindo a identificação de agrupamentos e o tratamento de nuances semânticas em textos interdisciplinares.

Esta pesquisa concentra-se no desenvolvimento de um \textit{pipeline} computacional para o mapeamento interativo de publicações científicas. A proposta central foi construir um artefato que combina a modelagem de tópicos do \gls{bertopic} \cite{Grootendorst_2022} com a ferramenta de visualização \gls{wizmap}\footnote{Disponível em: \url{https://github.com/poloclub/wizmap}.} \cite{Wang_2023}. O artefato computacional é aplicado ao acervo do Observatório de dados públicos de ciência e tecnologia da Bahia\footnote{Disponível em: \url{https://simcc.uesc.br/observatorio}.}, esse Observatório coleta informações de fontes como Currículos Lattes, Plataforma Sucupira e \textit{OpenAlex}, e tem um papel fundamental na gestão do conhecimento científico regional.

A metodologia \gls{dsr} é adotada como a estrutura principal deste estudo, orientando a criação do \textit{pipeline} como artefato principal resultado do trabalho. O objetivo foi transformar a base de dados textual do Observatório em um mapa de conhecimento navegável. Nessa solução, o \gls{bertopic} é empregado para extrair os padrões temáticos e o \gls{wizmap} é utilizado para a exploração visual e interativa desses tópicos. Essa integração visa permitir a identificação de temas e a compreensão da estrutura dos dados científicos da plataforma.

O trabalho está organizado da seguinte forma: O Capítulo 2 estabelece o Referencial Teórico, abordando os conceitos de Ciência da Informação, a arquitetura dos Transformadores e as técnicas de modelagem de tópicos. A seguir, o Capítulo 3 analisa os Trabalhos Correlatos, contextualizando esta pesquisa frente ao estado da arte. O Capítulo 4 detalha a Metodologia (\gls{dsr}). O Capítulo 5,descreve o Projeto de Desenvolvimento e a arquitetura do \textit{pipeline}. Por fim, o Capítulo 6 discute os Resultados e a validação da solução proposta.