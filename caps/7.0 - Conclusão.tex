\chapter[CONCLUSÃO]{CONCLUSÃO}
\label{chap:conclusao}

Este trabalho abordou o desafio de exploração de grandes acervos de publicações científicas, onde as abordagens tradicionais de busca lexical (palavras-chave) limitam a descoberta de conhecimento diante da sobrecarga de informação. O objetivo central consistiu no projeto, desenvolvimento e avaliação de um artefato computacional capaz de processar dados estruturados do Núcleo de Pesquisa Aplicada e Inovação (NPAI), servindo como prova de conceito para o Observatório de dados públicos da Bahia, apresentando-os na forma de um mapa de conhecimento interativo.

Para atingir esse objetivo, foi instanciado um \textit{pipeline} modular fundamentado em técnicas de \gls{pln}. Embora a orquestração de componentes como \gls{bertopic} e \gls{wizmap} possua precedentes na literatura, a contribuição deste estudo reside na adaptação metodológica necessária para operar em um \textit{corpus} de alta restrição (apenas títulos) e no idioma português. A avaliação demonstrou que a aplicação direta dessas ferramentas resultaria em ruído excessivo, sendo necessária a definição de uma heurística de configuração (ajuste de hiperparâmetros como \textit{min\_cluster\_size} e \gls{mmr}) capaz de extrair inteligência de dados esparsos.

A adoção da metodologia \gls{dsr} guiou a estrutura iterativa do trabalho, permitindo transitar entre a fundamentação teórica e o desenvolvimento prático. Isso garantiu que o artefato não fosse apenas uma implementação de software, mas uma proposta arquitetural validada tecnicamente para a lacuna de exploração semântica regional.

A avaliação do artefato (Capítulo \ref{chap:resultados}) demonstrou a viabilidade técnica da solução. A avaliação de desempenho indicou uma alta diversidade de tópicos (\textbf{0.9214}), sugerindo baixa sobreposição lexical. O escore de coerência \gls{npmi} (\textbf{-0.2639}) apresentou-se negativo, resultado compreendido como um \textit{trade-off} entre a coocorrência estatística (penalizada por títulos curtos) e a diversidade semântica buscada pelo algoritmo. A validação qualitativa, por meio de auditoria taxonômica e inspeção visual, corroborou a eficácia da solução, evidenciando que os tópicos gerados possuem coerência interpretativa e alinhamento com as grandes áreas do conhecimento.

Quanto às limitações, destaca-se que o uso exclusivo de títulos restringiu a janela de contexto para o modelo. Além disso, o artefato foi executado como um protótipo em ambiente controlado (NPAI). Portanto, os resultados atuais validam a tecnologia, mas não refletem toda a complexidade de um ambiente de produção em tempo real.

Conclui-se, portanto, que o estudo atingiu seu objetivo ao demonstrar a \textit{viabilidade técnica} da modelagem de tópicos baseada em embeddings como uma camada complementar à arquitetura de dados científicos. Os resultados obtidos na Prova de Conceito indicam que o pipeline é capaz de revelar agrupamentos semânticos latentes que não são capturados pela busca exata. Desta forma, o artefato apresenta-se como uma arquitetura funcional validada, instrumentalizando gestores e pesquisadores com uma ferramenta de apoio à decisão baseada em evidências, deixando a mensuração de eficiência operacional para trabalhos futuros.

\section[Trabalhos Futuros]{Trabalhos Futuros}
\label{sec:trabalhos_futuros}

As limitações identificadas durante o desenvolvimento e a natureza de protótipo deste estudo abrem caminho para diversas frentes de pesquisa que não foram abordadas nesta iteração:

\begin{itemize}
    \item \textbf{Enriquecimento Semântico (Full-Text):} Uma limitação central foi o uso exclusivo de títulos. Trabalhos futuros devem integrar o \textit{pipeline} aos resumos (\textit{abstracts}) das publicações. A hipótese é que textos mais longos forneçam contexto adicional, impactando positivamente as métricas estatísticas de coocorrência (\gls{npmi}) e refinando a densidade dos clusters.

    \item \textbf{Análise Temporal:} O estudo atual apresenta um \enquote{retrato estático} do acervo. Uma extensão promissora seria aplicar a variante dinâmica do \gls{bertopic} para visualizar a evolução dos temas ao longo do tempo (ex: o surgimento e declínio de termos como \enquote{COVID-19}), permitindo aos gestores identificar tendências emergentes ou obsoletas.

    \item \textbf{Validação com Usuários Reais:} Embora validado tecnicamente, o artefato carece de testes de usabilidade com os gestores do Observatório. Pesquisas futuras devem mensurar métricas de eficiência (tempo de descoberta) e satisfação do usuário para quantificar o ganho real em comparação ao sistema de busca tradicional.

    \item \textbf{Implementação de Busca Híbrida:} O desenvolvimento de um sistema que combine a precisão da busca lexical (palavras-chave) com a exploração semântica (mapa visual). Isso permitiria que o usuário filtrasse o mapa por um termo específico, unindo o melhor dos dois paradigmas de recuperação da informação.
    
    \item \textbf{Validação em Escala de Produção:} Aplicação do \textit{pipeline} sobre a totalidade do acervo do Observatório. Esta etapa exigirá o reajuste (\textit{tuning}) dos hiperparâmetros de modelagem para adequá-los ao volume massivo de dados, garantindo a escalabilidade da solução proposta.
\end{itemize}