\chapter[CONCLUSÃO]{CONCLUSÃO}
\label{chap:conclusao}

Este trabalho abordou o desafio de exploração de grandes acervos de publicações científicas, cujas abordagens tradicionais de busca lexical (palavras-chave) limitam a descoberta de conhecimento. O objetivo central consistiu no projeto, desenvolvimento e validação de um artefato computacional capaz de processar dados estruturados do Observatório de dados públicos de ciência e tecnologia da Bahia, e apresentá-los na forma de um mapa de conhecimento interativo.

Para atingir esse objetivo, foi implementado um \textit{pipeline} modular fundamentado em técnicas de Processamento de Linguagem Natural e Aprendizado de Máquina. A arquitetura da solução integrou o modelo \textit{BERTopic} para a identificação de tópicos, utilizando \textit{embeddings} contextuais (\textit{Sentence-BERT}), redução de dimensionalidade (\textit{UMAP}) e agrupamento baseado em densidade (\textit{HDBSCAN}). Adicionalmente, empregou-se o algoritmo MMR para o refinamento semântico dos rótulos e a ferramenta \textit{WizMap} para a visualização dos dados.

A adoção da metodologia \textit{Design Science Research} (DSR) mostrou-se adequada para a condução deste estudo, visto que a natureza do problema exigia a construção de uma solução tecnológica aplicável. A estrutura iterativa da DSR permitiu transitar entre a fundamentação teórica e o desenvolvimento prático, garantindo que o artefato desenvolvido não fosse apenas uma implementação de software, mas uma resposta validada cientificamente para a lacuna de exploração semântica identificada no Observatório.

A avaliação do artefato (Capítulo \ref{chap:resultados}), realizada sobre um \textit{dataset} de teste, demonstrou a viabilidade técnica da solução. A validação quantitativa (Seção \ref{sec:validacao_quantitativa}) indicou uma alta diversidade de tópicos (\textbf{0.9214}), sugerindo baixa sobreposição lexical entre os temas. O escore de coerência NPMI (\textbf{-0.2095}) apresentou-se negativo, resultado atribuído à natureza dos dados de entrada (títulos curtos) e à diferença entre a métrica estatística de coocorrência e a abordagem semântica do modelo. A validação qualitativa (Seção \ref{sec:validacao_qualitativa}) corroborou a eficácia da solução, evidenciando que os tópicos gerados possuem coerência interpretativa.

Quanto às limitações da pesquisa, é importante destacar que o uso apenas dos títulos restringiu a riqueza de informações disponíveis para o modelo, o que impactou as métricas estatísticas. Além disso, o artefato foi executado como um protótipo, isolado do fluxo de dados em tempo real do Observatório. Portanto, os resultados atuais servem como uma Prova de Conceito e não refletem toda a complexidade de um ambiente de produção em larga escala.

Conclui-se, portanto, que o artefato cumpre o papel de validar a hipótese de que a modelagem de tópicos baseada em \textit{embeddings} oferece uma alternativa funcional quando comparado a busca lexical, para a navegação exploratória em acervos científicos, desde que consideradas as limitações do volume e tipo de dados.

\section[Trabalhos Futuros]{Trabalhos Futuros}
\label{sec:trabalhos_futuros}

As limitações identificadas durante o desenvolvimento (Seção \ref{sec:limitacoes}) e a natureza de protótipo deste estudo abrem caminho para diversas frentes de trabalho futuro:

\begin{itemize}
    \item \textbf{Validação em Escala de Produção:} Aplicação do \textit{pipeline} sobre a totalidade do acervo do Observatório. Esta etapa exigirá o reajuste (\textit{tuning}) dos hiperparâmetros de modelagem (especialmente \textit{n\_neighbors} e \textit{min\_cluster\_size}) para adequá-los ao volume massivo de dados e evitar a fragmentação excessiva dos tópicos.

    \item \textbf{Enriquecimento Semântico:} Incluir os \textbf{resumos} (\textit{abstracts}) das publicações, além dos títulos, no processo de modelagem. Textos mais longos podem fornecer mais contexto, potencialmente gerando tópicos mais ricos e impactando positivamente as métricas de coerência estatística como o \gls{npmi}.

    \item \textbf{Integração Sistêmica:} Evolução do protótipo atual para um módulo de software integrado à arquitetura de \textit{backend} do Observatório, permitindo a atualização periódica e automatizada do mapa de conhecimento.
    
    \item \textbf{Personalização da Camada de Visualização:} Desenvolvimento de uma interface de visualização customizada ou adaptação profunda dos dados de entrada para o \textit{WizMap}. O objetivo é mitigar a rigidez dos algoritmos de resumo automático da ferramenta, garantindo que os rótulos hierárquicos (visualizados em \textit{zoom out}) respeitem estritamente a classificação semântica do \textit{BERTopic} e não sejam sobrepostos por termos de alta frequência, como nomes de autores.
\end{itemize}