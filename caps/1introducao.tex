\chapter[INTRODUÇÃO]{INTRODUÇÃO}
O cenário da pesquisa científica global tem testemunhado um crescimento exponencial nas últimas décadas, resultando em um vasto volume de dados que desafia os métodos tradicionais de organização e análise. Para navegar nessa imensidão de informações, pesquisadores confiam em plataformas de busca, como Web of Science, Scopus e IEEE Xplore, utilizando principalmente palavras-chave. Contudo, essa abordagem de recuperação de informações é limitada pela ambiguidade e pela diversidade do léxico científico, o que frequentemente resulta em buscas que não retornam a completude esperada e na dificuldade de identificar tendências emergentes na literatura \cite{Galli_2024}. A complexidade inerente a esses acervos de dados e a necessidade de uma análise mais profunda têm impulsionado o desenvolvimento e a aplicação de técnicas avançadas de Processamento de Linguagem Natural (\gls{PLN}) \cite{Datchanamoorthy_2023}.

Desta forma, o avanço das ferramentas associadas à ciência da informação, inteligência artificial e linguística computacional posiciona essas áreas como fundamentais na construção de soluções para a gestão do conhecimento acadêmico. Estudos como os de \cite{Mohammadi_2020}, que analisaram tendências de pesquisa em big data por meio de mineração de texto, e \cite{Xie_2020}, que exploraram tópicos monolíngues e multilíngues com \gls{LDA} e embeddings de \textit{BERT}, destacam a relevância da integração de técnicas de modelagem de tópicos com modelos baseados em transformadores.

Os Transformadores introduzidos por \cite{vaswani_2017}, com seu mecanismo de autoatenção (\textit{self-attention}), revolucionaram o campo da \gls{PLN} ao permitir que modelos como o \gls{BERT} capturassem relações contextuais em textos com alta eficiência \cite{Devlin_2019}. A partir dessa base, surgiram os embeddings, representações numéricas que codificam o significado semântico de palavras e frases, superando as limitações de modelos tradicionais de bag-of-words e de modelagem de tópicos como o \gls{LDA} \cite{Galli_2024}.

Nesse contexto, o BERTopic surge como uma abordagem moderna que se diferencia por utilizar os embeddings contextuais de modelos como o BERT para a modelagem de tópicos \cite{Grootendorst_2022}. Esta técnica permite identificar tópicos de forma dinâmica e mais coesa, superando as deficiências de modelos tradicionais em capturar nuances semânticas e lidar com a complexidade de textos interdisciplinares.

Apesar do avanço, a aplicação de novas técnicas em larga escala e a adaptação a bases de dados complexas ainda enfrentam desafios em escalabilidade e adaptação \cite{Datchanamoorthy_2023}. Estudos como o de \cite{Dillan_2023} mostram que a integração de transformadores com sistemas baseados em \textit{LLMs} (Large Language Models) como o \gls{GPT-4} pode melhorar a geração de \textit{embeddings} e a rotulagem de tópicos. No entanto, desafios como o ajuste de hiperparâmetros para maximizar a granularidade dos tópicos e a dependência de grandes volumes de dados rotulados permanecem obstáculos importantes \cite{Weng_2022}.

Este projeto de pesquisa aborda esse problema por meio do desenvolvimento de um pipeline que combina o BERTopic \cite{Grootendorst_2022} e o \gls{GPT-4} para a análise de publicações científicas aplicado à plataforma do \gls{SIMCC}, uma ferramenta que integra e centraliza dados de produção acadêmica de profissionais vinculados a instituições de ensino e pesquisa da Bahia. A plataforma, que coleta informações de fontes como Currículos Lattes, Sucupira e OpenAlex, tem um papel fundamental na gestão do conhecimento científico regional. O BERTopic é empregado para realizar a modelagem de tópicos a partir da base de dados, utilizando embeddings contextuais para identificar padrões temáticos de forma robusta e coerente. Complementarmente, o \gls{GPT-4} é utilizado para enriquecer a rotulagem dos tópicos, gerando rótulos descritivos e precisos que facilitam a interpretação dos resultados.

A metodologia (\gls{DSR}) é adotada como a estrutura principal deste estudo, orientando a criação de um artefato que visa resolver um problema prático por meio de uma solução híbrida. A pesquisa é estruturada em dois ciclos complementares: no primeiro, é desenvolvido o pipeline de modelagem de tópicos que combina o \textit{BERTopic} e o \textit{GPT-4} para extrair padrões temáticos da base de dados do \textit{SIMCC} e gerar representações semânticas enriquecidas. No segundo ciclo, o pipeline é integrado à plataforma, permitindo a identificação de temas emergentes de forma visual através de um \textit{WizMap}, um visualizador interativo e escalável para explorar grandes incorporações de aprendizado de máquina \cite{Wang_2023}. Este mecanismo otimiza a experiência dos usuários e contribui para a gestão estratégica da pesquisa na plataforma.